{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0aJe0maqZa71HG59gf7+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanzaniav0825/CS667/blob/main/Project_1_deliverables_3_ip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "SERPAPI_KEY = getpass(\"Enter your SerpAPI key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brH-Q0PyWBqr",
        "outputId": "05c64f05-2db3-4be1-915f-42662076e5ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your SerpAPI key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tldextract\n",
        "!pip install joblib\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSpMQqYdWTya",
        "outputId": "3caa404d-a607-4f8e-8641-bf7b3264ae3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tldextract\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract) (3.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from tldextract) (2.32.3)\n",
            "Collecting requests-file>=1.4 (from tldextract)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract) (3.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (2025.1.31)\n",
            "Downloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: requests-file, tldextract\n",
            "Successfully installed requests-file-2.1.0 tldextract-5.1.3\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aybpqGXyLRvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taMX5B4he2ia",
        "outputId": "01d615e2-53f6-4f8a-8135-3d89d6e1fe6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.1.31)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=08c75074a568f08f518b7ebe8ccadcd8d345aa4f0155ab8b5a2463229cb4f8fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import tldextract\n",
        "import re\n",
        "import random\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "class CredibilityScorer:\n",
        "    def __init__(self, url, serpapi_key=None):\n",
        "        self.url = url\n",
        "        self.serpapi_key = serpapi_key\n",
        "        self.domain_info = tldextract.extract(url)\n",
        "        self.domain = f\"{self.domain_info.domain}.{self.domain_info.suffix}\"\n",
        "        self.score = 0.0\n",
        "        self.explanation_parts = []\n",
        "\n",
        "    def domain_suffix_score(self): ...\n",
        "    def trusted_domain_score(self): ...\n",
        "    def recent_year_score(self): ...\n",
        "    def https_check(self): ...\n",
        "    def url_length_score(self): ...\n",
        "    def keyword_check(self): ...\n",
        "    def spam_word_check(self): ...\n",
        "    def ml_model_score(self): ...\n",
        "\n",
        "    def serpapi_credibility_score(self):\n",
        "        if not self.serpapi_key:\n",
        "            self.explanation_parts.append(\"üîç SERP analysis skipped (no API key provided).\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            params = {\n",
        "                \"q\": self.url,\n",
        "                \"api_key\": self.serpapi_key,\n",
        "                \"num\": 5\n",
        "            }\n",
        "            search = GoogleSearch(params)\n",
        "            results = search.get_dict()\n",
        "            found = False\n",
        "\n",
        "            for idx, result in enumerate(results.get(\"organic_results\", [])):\n",
        "                serp_url = result.get(\"link\", \"\")\n",
        "                serp_domain = tldextract.extract(serp_url)\n",
        "                serp_normalized = f\"{serp_domain.domain}.{serp_domain.suffix}\"\n",
        "\n",
        "                if serp_normalized == self.domain:\n",
        "                    found = True\n",
        "                    if idx == 0:\n",
        "                        self.score += 0.2\n",
        "                        self.explanation_parts.append(\"üîù URL appears as the top Google result.\")\n",
        "                    elif idx <= 2:\n",
        "                        self.score += 0.1\n",
        "                        self.explanation_parts.append(\"‚¨ÜÔ∏è URL ranks within top 3 Google results.\")\n",
        "                    else:\n",
        "                        self.explanation_parts.append(\"üîç URL found in lower Google results.\")\n",
        "\n",
        "                    title = result.get(\"title\", \"\").lower()\n",
        "                    snippet = result.get(\"snippet\", \"\").lower()\n",
        "                    if any(kw in title + snippet for kw in [\"study\", \"doi\", \"research\", \"journal\"]):\n",
        "                        self.score += 0.1\n",
        "                        self.explanation_parts.append(\"üìö SERP snippet contains scholarly language.\")\n",
        "                    if any(kw in title for kw in [\"miracle\", \"shocking\", \"click here\"]):\n",
        "                        self.score -= 0.2\n",
        "                        self.explanation_parts.append(\"üö´ Clickbait detected in SERP title.\")\n",
        "                    break\n",
        "\n",
        "            if not found:\n",
        "                self.explanation_parts.append(\"‚ö†Ô∏è Domain not matched in top Google search results.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.explanation_parts.append(f\"‚ö†Ô∏è SERP fetch failed: {str(e)}\")\n",
        "\n",
        "    def compute_star_rating(self):\n",
        "        if self.score >= 0.9:\n",
        "            return \"‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\"\n",
        "        elif self.score >= 0.75:\n",
        "            return \"‚≠ê‚≠ê‚≠ê‚≠ê\"\n",
        "        elif self.score >= 0.6:\n",
        "            return \"‚≠ê‚≠ê‚≠ê\"\n",
        "        elif self.score >= 0.4:\n",
        "            return \"‚≠ê‚≠ê\"\n",
        "        else:\n",
        "            return \"‚≠ê\"\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.domain_suffix_score()\n",
        "        self.trusted_domain_score()\n",
        "        self.recent_year_score()\n",
        "        self.https_check()\n",
        "        self.url_length_score()\n",
        "        self.keyword_check()\n",
        "        self.spam_word_check()\n",
        "        self.ml_model_score()\n",
        "        self.serpapi_credibility_score()\n",
        "\n",
        "        return {\n",
        "            \"url\": self.url,\n",
        "            \"score\": round(min(self.score, 1.0), 2),\n",
        "            \"stars\": self.compute_star_rating(),\n",
        "            \"explanation\": \" \".join(self.explanation_parts)\n",
        "        }\n",
        "\n",
        "# -------------------------------\n",
        "# üåê Streamlit App UI\n",
        "# -------------------------------\n",
        "st.set_page_config(page_title=\"Credibility Scorer\", page_icon=\"üîç\")\n",
        "st.title(\"üîç URL Credibility Scorer\")\n",
        "st.markdown(\"Evaluate the trustworthiness of any URL using rule-based and SERP-based analysis.\")\n",
        "\n",
        "url = st.text_input(\"üîó Enter a URL to evaluate:\")\n",
        "serpapi_key = st.text_input(\"üîê SerpAPI Key (optional for deeper analysis):\", type=\"password\")\n",
        "\n",
        "if st.button(\"Evaluate\"):\n",
        "    if not url.startswith(\"http\"):\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a full URL starting with http:// or https://\")\n",
        "    else:\n",
        "        scorer = CredibilityScorer(url, serpapi_key if serpapi_key else None)\n",
        "        result = scorer.evaluate()\n",
        "\n",
        "        st.markdown(f\"### ‚≠ê Credibility Score: `{result['stars']}` ({result['score']} / 1.0)\")\n",
        "        st.subheader(\"üìò Explanation\")\n",
        "        st.markdown(result[\"explanation\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l50A_SGLGv22",
        "outputId": "1088fb28-d134-47bd-83d1-613d64887b90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-04 18:47:46.776 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.779 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.782 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.783 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.784 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.785 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.789 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.791 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.791 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.793 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.795 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.797 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-04 18:47:46.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}